# Validation 및 InferenceTime 결과 비교 분석

## 1. Validation 추론 시간 비교 (평균 이미지당 시간, ms)

| 모델 | Alone (6_2) | Alone (6_1221) | Together (1) | Together (2) | Alone 평균 | Together 평균 | 차이 (Together - Alone) | 증가율 |
|------|-------------|----------------|-------------|--------------|------------|---------------|------------------------|--------|
| **cls** | 11.96 | 12.58 | 15.83 | 15.86 | 12.27 | 15.85 | +3.58 | **+29.2%** |
| **detect** | 26.75 | 28.32 | 48.42 | 47.74 | 27.54 | 48.08 | +20.54 | **+74.6%** |
| **pose** | 30.26 | 28.00 | 33.00 | 32.87 | 29.13 | 32.94 | +3.81 | **+13.1%** |
| **seg** | 36.16 | 38.49 | 46.41 | 41.11 | 37.33 | 43.76 | +6.43 | **+17.2%** |
| **obb** | 56.61 | 58.03 | 62.76 | 59.27 | 57.32 | 61.02 | +3.70 | **+6.5%** |

## 2. InferenceTime 동시 실행 비교 (MPS 사용/미사용)

### 2.1 추론 시간 비교표

| 모델 | Alone (평균) | MPS 사용 (평균) | MPS 미사용 (평균) | MPS 효과 | Alone 대비 (MPS 사용) | Alone 대비 (MPS 미사용) |
|------|--------------|-----------------|-------------------|----------|----------------------|------------------------|
| **cls** | 8.386 ms | **8.285 ms** | **6.677 ms** | **-19% (느림)** | +10% | -20% |
| **detect** | 27.027 ms | **30.249 ms** | **59.339 ms** | **+96% (빠름)** | +12% | +120% |
| **pose** | 27.234 ms | **23.534 ms** | **38.435 ms** | **+63% (빠름)** | -14% | +41% |
| **seg** | 33.100 ms | **31.270 ms** | **60.200 ms** | **+92% (빠름)** | -6% | +82% |
| **obb** | 26.085 ms | **22.515 ms** | **28.142 ms** | **+25% (빠름)** | -14% | +8% |

### 2.2 cls 모델이 MPS 사용 시 더 느려지는 이유

**cls 모델 특성:**
- 매우 가벼운 모델 (Alone: 8.4ms)
- GPU 연산량이 적음
- 빠르게 완료되는 작업

**MPS 미사용 시 cls가 빠른 이유:**
1. **빈틈 활용**: 다른 무거운 모델(detect, seg)이 GPU를 사용하는 동안 cls가 빠르게 실행
2. **짧은 실행 시간**: cls는 매우 빠르므로 컨텍스트 스위칭 오버헤드가 상대적으로 작음
3. **독립 실행**: MPS 미사용 시 각 프로세스가 독립적으로 실행되어 cls가 다른 모델의 대기 시간에 끼어들 수 있음

**MPS 사용 시 cls가 느려지는 이유:**
1. **MPS 오버헤드**: MPS 자체의 관리 오버헤드가 가벼운 작업에서는 부담이 됨
2. **공정한 스케줄링**: MPS는 모든 프로세스에 공정하게 GPU 리소스를 할당하므로, cls도 다른 모델과 동일한 대기 시간을 가짐
3. **작은 작업의 비효율**: 가벼운 작업에서는 MPS의 컨텍스트 스위칭 감소 효과가 오버헤드보다 작음

**결론:**
- cls는 매우 가벼운 모델이므로 MPS의 이점보다 오버헤드가 더 큼
- 무거운 모델(detect, seg, pose)은 MPS 사용 시 큰 성능 향상
- cls만 사용할 경우 MPS 미사용이 더 유리할 수 있음

## 3. 정확도/메트릭 비교

### Classification (cls)
- **Top-1 Accuracy**: 모든 실행에서 **0.74** (동일)
- **Top-5 Accuracy**: 모든 실행에서 **0.93** (동일)
- ✅ **정확도는 동일함** (병렬 실행이 정확도에 영향 없음)

### Detection (detect)
- **Precision**: 모든 실행에서 **0.8991** (동일)
- **Recall**: 모든 실행에서 **0.7241** (동일)
- **F1-Score**: 모든 실행에서 **0.8022** (동일)
- ✅ **정확도는 동일함**

### Pose Estimation (pose)
- **Precision**: 모든 실행에서 **0.8832** (동일)
- **Recall**: 모든 실행에서 **0.6585** (동일)
- **F1-Score**: 모든 실행에서 **0.7545** (동일)
- ✅ **정확도는 동일함**

### Segmentation (seg)
- **Precision**: 모든 실행에서 **0.9368** (동일)
- **Recall**: 모든 실행에서 **0.7059** (동일)
- **F1-Score**: 모든 실행에서 **0.8051** (동일)
- ✅ **정확도는 동일함**

### OBB (obb)
- **Total Detections**: 모든 실행에서 **1431** (동일)
- **Avg Detections/Image**: 모든 실행에서 **14.31** (동일)
- **oriented mAP@[0.5:0.95]**: Alone만 측정됨 (**0.7837**), Together는 측정 안됨
- ✅ **탐지 수는 동일함**

## 4. MPS (Multi-Process Service) 분석

### 4.1 MPS 효과 요약

| 모델 | MPS 효과 | 이유 |
|------|-----------|------|
| **detect** | ✅ **+96% 향상** | 무거운 모델, 컨텍스트 스위칭 오버헤드 감소 |
| **seg** | ✅ **+92% 향상** | 무거운 모델, GPU 메모리 경합 감소 |
| **pose** | ✅ **+63% 향상** | 중간 모델, 스케줄링 효율 향상 |
| **obb** | ✅ **+25% 향상** | 중간 모델, 약간의 성능 향상 |
| **cls** | ❌ **-19% 저하** | 가벼운 모델, MPS 오버헤드가 더 큼 |

### 4.2 GPU 사용률 분석 (tegrastats)

| 항목 | MPS 사용 | MPS 미사용 | 분석 |
|------|----------|------------|------|
| **GR3D_FREQ 평균 (전체)** | 14.39% | 29.69% | MPS 사용 시 더 낮은 평균 |
| **GR3D_FREQ 평균 (0이 아닌 샘플)** | 61.15% | 84.49% | MPS 미사용 시 높지만 비효율적 |
| **GR3D_FREQ 최대** | 99% | 98% | 유사 |
| **0이 아닌 샘플 수** | 48개 | 65개 | MPS 사용 시 더 효율적 |

**해석:**
- MPS 미사용 시 높은 GPU 사용률은 대기 시간 포함
- MPS 사용 시 낮은 사용률은 실제 작업에 집중
- 결과적으로 MPS 사용 시 더 빠른 추론 시간

### 4.3 MPS가 해결하는 병목 요인

#### A. GPU 컨텍스트 스위칭 오버헤드 감소
- **MPS 미사용**: 각 프로세스가 GPU를 독점적으로 사용하려 하며 컨텍스트 스위칭 발생
- **MPS 사용**: 단일 GPU 컨텍스트에서 멀티프로세싱으로 스위칭 오버헤드 감소

#### B. GPU 커널 실행 대기 시간 감소
- **MPS 미사용**: detect 59.6ms (alone 대비 +117%), seg 60.2ms (alone 대비 +82%)
- **MPS 사용**: detect 30.3ms (alone 대비 +10%), seg 31.9ms (alone 대비 -4%)

#### C. GPU 메모리 관리 최적화
- **MPS 미사용**: 각 프로세스가 독립적으로 GPU 메모리 할당/해제하며 경합 발생
- **MPS 사용**: 중앙화된 메모리 관리로 경합 감소

#### D. GPU 스케줄러 효율성 향상
- MPS는 GPU 작업을 더 효율적으로 스케줄링하여 실제 작업 시간에 집중

### 4.4 로그 오버헤드 분석

| 조건 | 모델 | 로그 없음 | 로그 있음 | 오버헤드 |
|------|------|-----------|-----------|----------|
| **MPS 사용** | cls | 8.328 ms | 8.243 ms | -0.085 ms (-1.0%) |
| | detect | 30.197 ms | 29.800 ms | -0.397 ms (-1.3%) |
| | pose | 23.732 ms | 23.825 ms | +0.093 ms (+0.4%) |
| | seg | 31.852 ms | 31.786 ms | -0.066 ms (-0.2%) |
| | obb | 22.869 ms | 22.327 ms | -0.542 ms (-2.4%) |
| **MPS 미사용** | cls | 6.783 ms | 6.572 ms | -0.211 ms (-3.1%) |
| | detect | 59.680 ms | 58.999 ms | -0.681 ms (-1.1%) |
| | pose | 39.014 ms | 37.857 ms | -1.157 ms (-3.0%) |
| | seg | 61.125 ms | 59.366 ms | -1.759 ms (-2.9%) |
| | obb | 25.566 ms | 28.620 ms | +3.054 ms (+12.0%) |

**결론:** vmstat/tegrastats 로그 수집은 성능에 거의 영향 없음 (±3% 이내)

### 4.5 vmstat 분석 결과

| 항목 | MPS 사용 | MPS 미사용 | 분석 |
|------|----------|------------|------|
| **CPU 사용률 (us)** | 3-54% | 2-53% | 유사 |
| **CPU 사용률 (sy)** | 1-12% | 1-16% | MPS 미사용 시 약간 높음 |
| **메모리 (free)** | 49-52GB | 49-53GB | 충분함 |
| **I/O 대기 (wa)** | 0-4% | 0-3% | 병목 없음 |

**결론:** CPU/메모리/I/O는 병목이 아님, GPU가 주요 병목

## 5. 주요 발견사항

### ✅ 긍정적 측면
1. **정확도 일관성**: 모든 모델에서 정확도/메트릭이 완전히 동일함
   - 병렬 실행이 모델의 정확도에 전혀 영향을 주지 않음
   - 결과의 신뢰성 확인

2. **Together 실행 간 일관성**: Together 1회차와 2회차 결과가 매우 유사
   - cls: 15.83ms vs 15.86ms (차이 0.03ms)
   - detect: 48.42ms vs 47.74ms (차이 0.68ms)
   - pose: 33.00ms vs 32.87ms (차이 0.13ms)
   - seg: 46.41ms vs 41.11ms (차이 5.30ms)
   - obb: 62.76ms vs 59.27ms (차이 3.49ms)

### ⚠️ 성능 저하
1. **추론 시간 증가**: 모든 모델에서 Together 실행 시 시간이 증가
   - **detect가 가장 큰 영향**: +74.6% 증가 (27.54ms → 48.08ms)
   - **cls도 상당한 증가**: +29.2% 증가 (12.27ms → 15.85ms)
   - **obb는 가장 적은 영향**: +6.5% 증가 (57.32ms → 61.02ms)

2. **GPU 병목 현상 확인**
   - 5개 모델이 동시에 실행되면서 GPU 리소스 경쟁 발생
   - detect와 cls가 가장 큰 영향을 받음 (상대적으로 빠른 모델)
   - obb는 이미 느린 모델이라 상대적 영향이 적음

## 6. 결론

### 정확도 측면
- ✅ **완벽한 일관성**: 병렬 실행이 정확도에 전혀 영향을 주지 않음
- ✅ **결과 신뢰성**: 모든 실행에서 동일한 메트릭 값

### 성능 측면
- ⚠️ **성능 저하 발생**: 병렬 실행 시 모든 모델에서 추론 시간 증가
- ⚠️ **GPU 병목 확인**: 5개 모델 동시 실행으로 인한 리소스 경쟁
- 📊 **영향도 차이**: 
  - detect: 가장 큰 영향 (+74.6%)
  - cls: 큰 영향 (+29.2%)
  - seg: 중간 영향 (+17.2%)
  - pose: 중간 영향 (+13.1%)
  - obb: 가장 적은 영향 (+6.5%)

### 권장사항

#### Validation 실행 시
1. **정확도 우선 시**: 병렬 실행 사용 가능 (정확도 영향 없음)
2. **성능 우선 시**: 순차 실행 권장 (더 빠른 추론 시간)
3. **균형잡힌 접근**: 중요 모델은 순차 실행, 나머지는 병렬 실행

#### InferenceTime 동시 실행 시
1. **MPS 사용 권장 모델**: detect, seg, pose, obb
   - detect: +96% 성능 향상 (59.3ms → 30.2ms)
   - seg: +92% 성능 향상 (60.2ms → 31.3ms)
   - pose: +63% 성능 향상 (38.4ms → 23.5ms)
   - obb: +25% 성능 향상 (28.1ms → 22.5ms)

2. **MPS 미사용 권장 모델**: cls
   - cls: MPS 사용 시 -19% 성능 저하 (6.7ms → 8.3ms)
   - 가벼운 모델이므로 MPS 오버헤드가 상대적으로 더 큼

### 6.3 가벼운 모델에서 MPS 오버헤드가 상대적으로 큰 이유

#### A. 절대적 오버헤드 vs 상대적 오버헤드

**MPS의 절대적 오버헤드:**
- MPS 관리 오버헤드: 약 0.5-1.5ms (모든 모델에 동일)
- 컨텍스트 스위칭 감소 이점: 무거운 모델에서 더 큼

**상대적 영향:**
- **cls (8.4ms)**: 1.5ms 오버헤드 = **18% 증가**
- **detect (27ms)**: 1.5ms 오버헤드 = **5.6% 증가**
- **seg (33ms)**: 1.5ms 오버헤드 = **4.5% 증가**

**결론:** 절대적 오버헤드는 비슷하지만, 가벼운 모델에서는 상대적 비율이 훨씬 큼

#### B. MPS의 이점이 가벼운 모델에서는 작음

**무거운 모델 (detect, seg)에서 MPS 이점:**
- 컨텍스트 스위칭 오버헤드: 20-30ms 감소
- MPS 오버헤드: 1.5ms
- **순 이익: +18-28ms** ✅

**가벼운 모델 (cls)에서 MPS 이점:**
- 컨텍스트 스위칭 오버헤드: 0.5-1ms 감소 (이미 빠름)
- MPS 오버헤드: 1.5ms
- **순 손실: -0.5~-1ms** ❌

#### C. 빈틈 활용 (Gap Utilization) 효과

**MPS 미사용 시:**
```
시간축: 0ms -------- 30ms -------- 60ms -------- 90ms
detect:  [======== GPU 사용 ========]
cls:     [빠르게 실행] (detect 대기 시간 활용)
seg:     [======== GPU 사용 ========]
```
- cls는 다른 모델의 GPU 대기 시간에 끼어들어 빠르게 실행 가능
- 총 실행 시간: 90ms (cls는 거의 추가 시간 없음)

**MPS 사용 시:**
```
시간축: 0ms -------- 30ms -------- 60ms -------- 90ms
모든 모델: [공정한 스케줄링으로 순차 실행]
```
- cls도 다른 모델과 동일한 대기 시간을 가짐
- 총 실행 시간: 90ms + cls 대기 시간

#### D. 실행 시간 대비 오버헤드 비율

| 모델 | 실행 시간 | MPS 오버헤드 | 오버헤드 비율 | MPS 이점 | 순 효과 |
|------|-----------|--------------|---------------|----------|---------|
| **cls** | 8.4ms | ~1.5ms | **18%** | ~0.5ms | **-1.0ms** ❌ |
| **detect** | 27ms | ~1.5ms | **5.6%** | ~20ms | **+18.5ms** ✅ |
| **seg** | 33ms | ~1.5ms | **4.5%** | ~25ms | **+23.5ms** ✅ |
| **pose** | 28ms | ~1.5ms | **5.4%** | ~15ms | **+13.5ms** ✅ |

**핵심:**
- 가벼운 모델: 오버헤드 비율이 크고, MPS 이점이 작음 → **순 손실**
- 무거운 모델: 오버헤드 비율이 작고, MPS 이점이 큼 → **순 이익**

#### E. 스케줄링 효율성 차이

**가벼운 모델 (cls):**
- 실행 시간이 짧아 스케줄링 오버헤드가 상대적으로 큼
- MPS의 공정한 스케줄링이 오히려 불리함
- 독립 실행 시 더 빠르게 완료 가능

**무거운 모델 (detect, seg):**
- 실행 시간이 길어 스케줄링 오버헤드가 상대적으로 작음
- MPS의 공정한 스케줄링이 컨텍스트 스위칭 감소로 큰 이익
- 공유 컨텍스트에서 더 효율적

### 결론

가벼운 모델에서 MPS 오버헤드가 상대적으로 큰 이유:
1. **절대적 오버헤드는 비슷하지만 상대적 비율이 큼** (18% vs 5%)
2. **MPS의 이점이 가벼운 모델에서는 작음** (0.5ms vs 20ms)
3. **빈틈 활용 효과가 MPS 사용 시 사라짐**
4. **스케줄링 오버헤드가 짧은 실행 시간에서 상대적으로 큼**

따라서 **cls 같은 가벼운 모델은 MPS 미사용이 유리**하고, **무거운 모델은 MPS 사용이 유리**합니다.

3. **혼합 전략**:
   - 무거운 모델(detect, seg, pose, obb): MPS 사용
   - 가벼운 모델(cls): MPS 미사용 또는 별도 실행

4. **로그 수집**: vmstat/tegrastats 로그 수집은 성능에 거의 영향 없으므로 분석을 위해 수집 권장


