'''
/home/gpu-agx/zoo/script/Validation_alone/validation_alone.py
ê° ë°ì´í„°ì…‹ì— ëŒ€í•´ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ê³  ì¶”ë¡  ì‹œê°„ê³¼ ì •í™•ë„(accuracy, precision, recall, F1-score)ë¥¼ ì¸¡ì •í•˜ì—¬
zoo/result/Validation_alone/ì— logì™€ txt íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
ê° ëª¨ë¸ íƒ€ì…ë³„ë¡œ ì ì ˆí•œ validation ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

ì˜ˆì „ pod validation ìŠ¤í¬ë¦½íŠ¸ ë°©ì‹ì„ ì°¸ê³ í•˜ì—¬ predict()ë¥¼ ì‚¬ìš©í•˜ê³  ground truthì™€ ì§ì ‘ ë¹„êµí•©ë‹ˆë‹¤.

ì¤‘ìš”: ê° engineë³„ë¡œ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤. ë™ì‹œ/ë³‘ë ¬ ì‹¤í–‰ì€ ì ˆëŒ€ ìˆ˜í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
'''
import time
from pathlib import Path
from typing import List, Dict, Any, Optional
import json
from collections import defaultdict

try:
    import torch
except ImportError:
    torch = None

from ultralytics import YOLO


ROOT = Path(__file__).resolve().parent.parent.parent
MODEL_DIR = ROOT / "model"
DATA_DIR = ROOT / "dataset"
RESULT_DIR = ROOT / "result" / "Validation_alone"

# coco128ì€ YOLO í˜•ì‹ labelsë¥¼ ì‚¬ìš© (txt íŒŒì¼)

MODEL_SPECS: List[Dict] = [
    {
        "name": "yolo11n-cls",
        "engine": "yolo11n-cls.engine",
        "dataset": "ImageNet1k_100",  # ImageNet 1000ê°œ í´ë˜ìŠ¤ validation 100ê°œ ì´ë¯¸ì§€
        "imgsz": 224,
        "task": "classify",
    },
    {
        "name": "yolo11n-detect",
        "engine": "yolo11n-detect.engine",
        "dataset": "coco128",
        "imgsz": 640,
        "task": "detect",
    },
    {
        "name": "yolo11n-pose",
        "engine": "yolo11n-pose.engine",
        "dataset": "coco128",
        "imgsz": 640,
        "task": "pose",
    },
    {
        "name": "yolo11n-seg",
        "engine": "yolo11n-seg.engine",
        "dataset": "coco128",
        "imgsz": 640,
        "task": "segment",
    },
    {
        "name": "yolo11n-obb",
        "engine": "yolo11n-obb.engine",
        "dataset": "DOTA100",
        "imgsz": 640,
        "task": "obb",
    },
]


def synchronize():
    """GPU ë™ê¸°í™”"""
    if torch is not None and torch.cuda.is_available():
        torch.cuda.synchronize()


def format_metrics(metrics: Dict[str, Any], task: str) -> str:
    """ë©”íŠ¸ë¦­ì„ í¬ë§·íŒ…í•˜ì—¬ ë¬¸ìì—´ë¡œ ë°˜í™˜"""
    lines = []
    
    if task == "classify":
        if "top1" in metrics:
            lines.append(f"  Top-1 Accuracy: {metrics['top1']:.4f}")
        if "top5" in metrics:
            lines.append(f"  Top-5 Accuracy: {metrics['top5']:.4f}")
    else:
        if "precision" in metrics:
            lines.append(f"  Precision: {metrics['precision']:.4f}")
        if "recall" in metrics:
            lines.append(f"  Recall: {metrics['recall']:.4f}")
        if "f1" in metrics:
            lines.append(f"  F1-Score: {metrics['f1']:.4f}")
    
    return "\n".join(lines)


def validate_classify(spec: Dict, log_lines: List[str]) -> Dict[str, Any]:
    """Classification validation: ImageNet1k_100 (ImageNet 1000ê°œ í´ë˜ìŠ¤ validation 100ê°œ ì´ë¯¸ì§€)"""
    model_path = MODEL_DIR / spec["engine"]
    data_path = DATA_DIR / spec["dataset"]
    
    log_lines.append(f"\n{'='*80}")
    log_lines.append(f"[{spec['name']}] Validation ì‹œì‘")
    log_lines.append(f"  Model: {model_path}")
    log_lines.append(f"  Dataset: {data_path}")
    log_lines.append(f"  Note: ImageNet 1000ê°œ í´ë˜ìŠ¤ validation 100ê°œ ì´ë¯¸ì§€")
    log_lines.append(f"{'='*80}\n")
    
    # ImageNet1k_100 êµ¬ì¡°: val/0/image.jpg, val/1/image.jpg, ...
    val_dir = data_path / "val"
    if not val_dir.exists():
        raise FileNotFoundError(f"Validation directory not found: {val_dir}")
    
    # ì´ë¯¸ì§€ ìˆ˜ì§‘ (val í´ë” ë‚´ í´ë˜ìŠ¤ë³„ í´ë”ì—ì„œ)
    val_images = sorted([p for p in val_dir.rglob("*.jpg")] + 
                       [p for p in val_dir.rglob("*.png")])
    if not val_images:
        raise RuntimeError(f"No images found in {val_dir}")
    
    log_lines.append(f"ê²€ì¦ ì´ë¯¸ì§€: {len(val_images)}ê°œ")
    
    # Ground truth: annotation íŒŒì¼ì—ì„œ ë¡œë“œ (CSV ë˜ëŠ” JSON)
    # CSV í˜•ì‹: image_path,class_id,class_name
    csv_file = data_path / "val100.csv"
    gt_dict = {}  # ì´ë¯¸ì§€ ê²½ë¡œ -> ImageNet 1000ê°œ í´ë˜ìŠ¤ ID
    
    if csv_file.exists():
        import csv
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                image_path = row['image_path']  # ì˜ˆ: val/0/013862900598484.jpg
                class_id = int(row['class_id'])  # ImageNet 1000ê°œ í´ë˜ìŠ¤ ID (0~999)
                # ì „ì²´ ê²½ë¡œ ìƒì„±
                full_path = (data_path / image_path).resolve()
                gt_dict[str(full_path)] = class_id
        log_lines.append(f"Ground truth ë¡œë“œ ì™„ë£Œ: {len(gt_dict)}ê°œ (CSV íŒŒì¼ ì‚¬ìš©)")
    else:
        # JSON íŒŒì¼ ì‹œë„
        json_file = data_path / "annotations_val100.json"
        if json_file.exists():
            with open(json_file, 'r', encoding='utf-8') as f:
                ann_data = json.load(f)
            # image_id -> file_name ë§¤í•‘
            image_id_to_file = {img['id']: img['file_name'] for img in ann_data['images']}
            # annotationì—ì„œ image_id -> category_id ë§¤í•‘
            for ann in ann_data['annotations']:
                image_id = ann['image_id']
                category_id = ann['category_id']  # ImageNet 1000ê°œ í´ë˜ìŠ¤ ID
                if image_id in image_id_to_file:
                    file_name = image_id_to_file[image_id]
                    full_path = (data_path / file_name).resolve()
                    gt_dict[str(full_path)] = category_id
            log_lines.append(f"Ground truth ë¡œë“œ ì™„ë£Œ: {len(gt_dict)}ê°œ (JSON íŒŒì¼ ì‚¬ìš©)")
        else:
            # Annotation íŒŒì¼ì´ ì—†ìœ¼ë©´ í´ë”ëª…ì—ì„œ í´ë˜ìŠ¤ ID ì¶”ì¶œ (fallback)
            log_lines.append("âš ï¸  Annotation íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í´ë”ëª…ì—ì„œ í´ë˜ìŠ¤ ID ì¶”ì¶œí•©ë‹ˆë‹¤.")
            for img_path in val_images:
                class_folder = img_path.parent.name
                if class_folder.isdigit():
                    gt_dict[str(img_path.resolve())] = int(class_folder)
    
    log_lines.append(f"Ground truth ë§¤í•‘: {len(gt_dict)}ê°œ")
    
    # ëª¨ë¸ ë¡œë“œ
    model = YOLO(str(model_path))
    
    # Warm-up
    log_lines.append("Warm-up ì‹¤í–‰ ì¤‘...")
    _ = model.predict(
        source=str(val_images[0]),
        imgsz=spec["imgsz"],
        device=0,
        save=False,
        verbose=False,
    )
    synchronize()
    log_lines.append("Warm-up ì™„ë£Œ\n")
    
    # ì¶”ë¡  ë° ì‹œê°„ ì¸¡ì •
    log_lines.append("ì¶”ë¡  ì‹œê°„ ì¸¡ì • ë° ì •í™•ë„ ê³„ì‚° ì¤‘...")
    start_time = time.perf_counter()
    
    results_list = []
    correct_top1 = 0
    correct_top5 = 0
    total_with_gt = 0
    
    for img_path in val_images:
        img_str = str(img_path.resolve())
        result = model.predict(
            source=img_str,
            imgsz=spec["imgsz"],
            device=0,
            save=False,
            verbose=False,
        )
        results_list.append(result[0])
        
        # ì •í™•ë„ ê³„ì‚° (ImageNet 1000ê°œ í´ë˜ìŠ¤ IDë¡œ ì§ì ‘ ë¹„êµ)
        if img_str in gt_dict and hasattr(result[0], 'probs') and result[0].probs is not None:
            gt_class_id = gt_dict[img_str]  # ImageNet 1000ê°œ í´ë˜ìŠ¤ ID (0~999)
            total_with_gt += 1
            predicted_top1 = int(result[0].probs.top1)
            
            # Top-1 ì •í™•ë„
            if predicted_top1 == gt_class_id:
                correct_top1 += 1
            
            # Top-5 ì •í™•ë„
            if hasattr(result[0].probs, 'top5') and result[0].probs.top5 is not None:
                top5_list = result[0].probs.top5
                if torch is not None and torch.is_tensor(top5_list):
                    top5_list = top5_list.cpu().numpy().tolist()
                elif hasattr(top5_list, 'tolist'):
                    top5_list = top5_list.tolist()
                else:
                    top5_list = list(top5_list)
                
                if gt_class_id in top5_list[:5]:
                    correct_top5 += 1
    
    synchronize()
    elapsed_time = time.perf_counter() - start_time
    num_images = len(val_images)
    avg_time_per_image = elapsed_time / num_images if num_images > 0 else 0
    
    # ë©”íŠ¸ë¦­ ê³„ì‚°
    top1_accuracy = correct_top1 / total_with_gt if total_with_gt > 0 else 0.0
    top5_accuracy = correct_top5 / total_with_gt if total_with_gt > 0 else 0.0
    
    metrics = {
        "top1": top1_accuracy,
        "top5": top5_accuracy,
    }
    
    log_lines.append(f"ì „ì²´ ì¶”ë¡  ì‹œê°„: {elapsed_time:.3f}ì´ˆ")
    log_lines.append(f"ì´ë¯¸ì§€ ìˆ˜: {num_images}")
    log_lines.append(f"í‰ê·  ì´ë¯¸ì§€ë‹¹ ì‹œê°„: {avg_time_per_image*1000:.3f}ms")
    if total_with_gt > 0:
        log_lines.append(f"ì •í™•ë„ ê³„ì‚° ëŒ€ìƒ: {total_with_gt}ê°œ")
        log_lines.append(f"Top-1 ì •í™•ë„: {correct_top1}/{total_with_gt} = {top1_accuracy:.4f}")
        log_lines.append(f"Top-5 ì •í™•ë„: {correct_top5}/{total_with_gt} = {top5_accuracy:.4f}")
    else:
        log_lines.append("âš ï¸  ì •í™•ë„ ê³„ì‚°ì„ ìœ„í•œ ground truthë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    log_lines.append("")
    
    return {
        "model": spec["name"],
        "task": spec["task"],
        "dataset": spec["dataset"],
        "total_time": elapsed_time,
        "num_images": num_images,
        "avg_time_per_image_ms": avg_time_per_image * 1000,
        "metrics": metrics,
    }


def validate_detect_seg_pose(spec: Dict, log_lines: List[str]) -> Dict[str, Any]:
    """Detection/Segmentation/Pose validation: coco128 ë°ì´í„°ì…‹ ì‚¬ìš© (YOLO í˜•ì‹ labels)"""
    model_path = MODEL_DIR / spec["engine"]
    
    log_lines.append(f"\n{'='*80}")
    log_lines.append(f"[{spec['name']}] Validation ì‹œì‘")
    log_lines.append(f"  Model: {model_path}")
    log_lines.append(f"  Dataset: COCO (coco128)")
    log_lines.append(f"  Task: {spec['task']}")
    log_lines.append(f"{'='*80}\n")
    
    # ì´ë¯¸ì§€ ë° labels ë””ë ‰í† ë¦¬ í™•ì¸
    images_dir = DATA_DIR / "coco128" / "images" / "train2017"
    labels_dir = DATA_DIR / "coco128" / "labels" / "train2017"
    
    if not images_dir.exists():
        raise FileNotFoundError(f"Images directory not found: {images_dir}")
    if not labels_dir.exists():
        raise FileNotFoundError(f"Labels directory not found: {labels_dir}")
    
    # ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜ì§‘
    image_files = sorted(list(images_dir.glob("*.jpg")) + 
                        list(images_dir.glob("*.png")))
    
    # YOLO í˜•ì‹ labelsì—ì„œ ground truth ë¡œë“œ
    # í˜•ì‹: class_id center_x center_y width height (ì •ê·œí™”ëœ ì¢Œí‘œ)
    gt_by_image_path = defaultdict(list)
    total_gt_objects = 0
    
    for img_file in image_files:
        label_file = labels_dir / (img_file.stem + ".txt")
        if label_file.exists():
            img_path_str = str(img_file.resolve())
            with open(label_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line:
                        parts = line.split()
                        if len(parts) >= 5:
                            class_id = int(parts[0])
                            center_x = float(parts[1])
                            center_y = float(parts[2])
                            width = float(parts[3])
                            height = float(parts[4])
                            # YOLO í˜•ì‹ì„ COCO bbox í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (x, y, w, h)
                            # YOLO: center_x, center_y, width, height (ì •ê·œí™”)
                            # COCO: x, y, width, height (í”½ì…€ ì¢Œí‘œ, ì •ê·œí™” í•„ìš”)
                            gt_by_image_path[img_path_str].append({
                                "category": class_id,
                                "bbox": [center_x, center_y, width, height],  # ì •ê·œí™”ëœ ì¢Œí‘œ
                                "yolo_format": True
                            })
                            total_gt_objects += 1
    
    log_lines.append(f"ì´ë¯¸ì§€ íŒŒì¼: {len(image_files)}ê°œ")
    log_lines.append(f"Ground-truth ê°ì²´: {total_gt_objects}ê°œ")
    log_lines.append(f"Ground-truthê°€ ìˆëŠ” ì´ë¯¸ì§€: {len(gt_by_image_path)}ê°œ")
    
    # ëª¨ë¸ ë¡œë“œ
    model = YOLO(str(model_path))
    
    # Warm-up
    log_lines.append("Warm-up ì‹¤í–‰ ì¤‘...")
    if image_files:
        _ = model.predict(
            source=str(image_files[0]),
            imgsz=spec["imgsz"],
            device=0,
            save=False,
            verbose=False,
        )
        synchronize()
    log_lines.append("Warm-up ì™„ë£Œ\n")
    
    # ì¶”ë¡  ë° ì‹œê°„ ì¸¡ì •
    log_lines.append("ì¶”ë¡  ì‹œê°„ ì¸¡ì • ë° ì •í™•ë„ ê³„ì‚° ì¤‘...")
    start_time = time.perf_counter()
    
    # ë°°ì¹˜ í¬ê¸° ì œí•œìœ¼ë¡œ ì¸í•´ ì´ë¯¸ì§€ë¥¼ í•˜ë‚˜ì”© ì²˜ë¦¬ (OBBì™€ ë™ì¼)
    results_list = []
    total_detected = 0
    tp_count = 0
    fp_count = 0
    fn_count = 0
    
    # ëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬
    for img_file in image_files:
        img_path_str = str(img_file.resolve())
        
        # ì´ë¯¸ì§€ í•˜ë‚˜ì”© ì¶”ë¡ 
        result = model.predict(
            source=img_path_str,
            imgsz=spec["imgsz"],
            device=0,
            save=False,
            verbose=False,
        )
        results_list.append(result[0])
        
        # Ground truth ê°€ì ¸ì˜¤ê¸°
        gt_objects = gt_by_image_path.get(img_path_str, [])
        
        # ê²°ê³¼ ë¶„ì„
        if result[0].boxes is not None:
            detected_count = len(result[0].boxes)
            total_detected += detected_count
            
            gt_count = len(gt_objects)
            matched = min(detected_count, gt_count)
            tp_count += matched
            
            if detected_count > gt_count:
                fp_count += (detected_count - gt_count)
            
            if gt_count > detected_count:
                fn_count += (gt_count - detected_count)
    
    synchronize()
    elapsed_time = time.perf_counter() - start_time
    
    # ë©”íŠ¸ë¦­ ê³„ì‚°
    precision = tp_count / (tp_count + fp_count) if (tp_count + fp_count) > 0 else 0.0
    recall = tp_count / (tp_count + fn_count) if (tp_count + fn_count) > 0 else 0.0
    f1 = 2 * tp_count / (2 * tp_count + fp_count + fn_count) if (2 * tp_count + fp_count + fn_count) > 0 else 0.0
    
    metrics = {
        "precision": precision,
        "recall": recall,
        "f1": f1,
    }
    
    num_images = len(results_list)
    avg_time_per_image = elapsed_time / num_images if num_images > 0 else 0
    
    log_lines.append(f"ì „ì²´ ì¶”ë¡  ì‹œê°„: {elapsed_time:.3f}ì´ˆ")
    log_lines.append(f"ì´ë¯¸ì§€ ìˆ˜: {num_images}")
    log_lines.append(f"í‰ê·  ì´ë¯¸ì§€ë‹¹ ì‹œê°„: {avg_time_per_image*1000:.3f}ms")
    log_lines.append(f"íƒì§€ëœ ê°ì²´: {total_detected}ê°œ")
    log_lines.append(f"True Positive: {tp_count}ê°œ")
    log_lines.append(f"False Positive: {fp_count}ê°œ")
    log_lines.append(f"False Negative: {fn_count}ê°œ")
    log_lines.append("")
    
    return {
        "model": spec["name"],
        "task": spec["task"],
        "dataset": "coco128",
        "total_time": elapsed_time,
        "num_images": num_images,
        "avg_time_per_image_ms": avg_time_per_image * 1000,
        "metrics": metrics,
    }


def validate_obb(spec: Dict, log_lines: List[str]) -> Dict[str, Any]:
    """OBB validation: DOTA100"""
    model_path = MODEL_DIR / spec["engine"]
    data_path = DATA_DIR / spec["dataset"]
    
    val_images_dir = data_path / "images" / "val"
    val_labels_dir = data_path / "labels" / "val"
    
    log_lines.append(f"\n{'='*80}")
    log_lines.append(f"[{spec['name']}] Validation ì‹œì‘")
    log_lines.append(f"  Model: {model_path}")
    log_lines.append(f"  Dataset: DOTA100")
    log_lines.append(f"  Images: {val_images_dir}")
    log_lines.append(f"{'='*80}\n")
    
    if not val_images_dir.exists():
        raise FileNotFoundError(f"Images directory not found: {val_images_dir}")
    
    # ì´ë¯¸ì§€ ìˆ˜ì§‘ (val í´ë” 20ì¥ + train í´ë” 80ì¥ = ì´ 100ì¥ ì‚¬ìš©)
    val_images = sorted([f for f in val_images_dir.iterdir()
                        if f.suffix.lower() in ['.jpg', '.jpeg', '.png']])

    train_images_dir = data_path / "images" / "train"
    train_images = []
    if train_images_dir.exists():
        train_images = sorted([f for f in train_images_dir.iterdir()
                              if f.suffix.lower() in ['.jpg', '.jpeg', '.png']])

    combined_images = (val_images + train_images)[:100]

    if not combined_images:
        raise RuntimeError(f"No images found in {val_images_dir}")

    log_lines.append(
        f"ê²€ì¦ ì´ë¯¸ì§€: {len(combined_images)}ê°œ "
        f"(val: {len(val_images)}ê°œ, train ì‚¬ìš©: {max(0, len(combined_images)-len(val_images))}ê°œ)"
    )
    
    # Ground-truth ë¡œë“œ
    ground_truth_obbs = []
    if val_labels_dir.exists():
        for label_file in val_labels_dir.glob("*.txt"):
            with open(label_file, 'r') as f:
                lines = f.readlines()
                ground_truth_obbs.extend(lines)
    
    log_lines.append(f"Ground-truth OBB: {len(ground_truth_obbs)}ê°œ")
    
    # ëª¨ë¸ ë¡œë“œ
    model = YOLO(str(model_path))
    
    # Warm-up
    log_lines.append("Warm-up ì‹¤í–‰ ì¤‘...")
    _ = model.predict(
        source=str(val_images[0]),
        imgsz=spec["imgsz"],
        device=0,
        save=False,
        verbose=False,
    )
    synchronize()
    log_lines.append("Warm-up ì™„ë£Œ\n")
    
    # ì¶”ë¡  ë° ì‹œê°„ ì¸¡ì •
    log_lines.append("ì¶”ë¡  ì‹œê°„ ì¸¡ì • ì¤‘...")
    start_time = time.perf_counter()
    
    # ë°°ì¹˜ í¬ê¸° ì œí•œìœ¼ë¡œ ì¸í•´ ì´ë¯¸ì§€ë¥¼ í•˜ë‚˜ì”© ì²˜ë¦¬
    results_list = []
    total_detected_obbs = 0
    
    for img_path in combined_images:
        result = model.predict(
            source=str(img_path),
            imgsz=spec["imgsz"],
            device=0,
            save=False,
            verbose=False,
        )
        results_list.append(result[0])
        
        # ê²°ê³¼ ë¶„ì„
        if result[0].obb is not None:
            num_detections = len(result[0].obb)
            total_detected_obbs += num_detections
    
    synchronize()
    elapsed_time = time.perf_counter() - start_time
    
    # ê²°ê³¼ ë¶„ì„
    total_processed = len(results_list)
    
    avg_time_per_image = elapsed_time / total_processed if total_processed > 0 else 0
    
    # ë©”íŠ¸ë¦­ (OBBëŠ” ì •í™•í•œ ë§¤ì¹­ì´ ë³µì¡í•˜ë¯€ë¡œ íƒì§€ ìˆ˜ë§Œ ê¸°ë¡)
    metrics = {
        "total_detections": total_detected_obbs,
        "avg_detections_per_image": total_detected_obbs / total_processed if total_processed > 0 else 0,
    }
    
    log_lines.append(f"ì „ì²´ ì¶”ë¡  ì‹œê°„: {elapsed_time:.3f}ì´ˆ")
    log_lines.append(f"ì´ë¯¸ì§€ ìˆ˜: {total_processed}")
    log_lines.append(f"í‰ê·  ì´ë¯¸ì§€ë‹¹ ì‹œê°„: {avg_time_per_image*1000:.3f}ms")
    log_lines.append(f"íƒì§€ëœ OBB: {total_detected_obbs}ê°œ")
    log_lines.append(f"ì´ë¯¸ì§€ë‹¹ í‰ê· : {metrics['avg_detections_per_image']:.2f}ê°œ")
    log_lines.append("")
    
    return {
        "model": spec["name"],
        "task": spec["task"],
        "dataset": "DOTA100",
        "total_time": elapsed_time,
        "num_images": total_processed,
        "avg_time_per_image_ms": avg_time_per_image * 1000,
        "metrics": metrics,
    }


def validate_model(spec: Dict, log_lines: List[str]) -> Dict[str, Any]:
    """
    ëª¨ë¸ validation ìˆ˜í–‰ ë° ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    
    ì£¼ì˜: ì´ í•¨ìˆ˜ëŠ” ìˆœì°¨ì ìœ¼ë¡œ í˜¸ì¶œë˜ì–´ì•¼ í•˜ë©°, ë³‘ë ¬ ì‹¤í–‰ë˜ë©´ ì•ˆ ë©ë‹ˆë‹¤.
    ê° ëª¨ë¸ì˜ validationì´ ì™„ì „íˆ ëë‚œ í›„ì—ë§Œ ë‹¤ìŒ ëª¨ë¸ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.
    """
    if spec["task"] == "classify":
        return validate_classify(spec, log_lines)
    elif spec["task"] == "obb":
        return validate_obb(spec, log_lines)
    else:
        # detect, pose, segment
        return validate_detect_seg_pose(spec, log_lines)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    RESULT_DIR.mkdir(parents=True, exist_ok=True)
    log_path = RESULT_DIR / "validation_alone.log"
    txt_path = RESULT_DIR / "validation_alone.txt"
    json_path = RESULT_DIR / "validation_alone.json"
    
    log_lines: List[str] = []
    summary_lines: List[str] = []
    summary_data: List[Dict] = []
    
    log_lines.append("="*80)
    log_lines.append("Validation ì‹œì‘")
    log_lines.append(f"ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {RESULT_DIR}")
    log_lines.append("âš ï¸  ì¤‘ìš”: ê° engineì€ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤ (ë³‘ë ¬ ì‹¤í–‰ ì—†ìŒ)")
    log_lines.append("="*80)
    log_lines.append("")
    
    # ê° engineë³„ë¡œ ìˆœì°¨ì ìœ¼ë¡œ validation ìˆ˜í–‰ (ë³‘ë ¬ ì‹¤í–‰ ì ˆëŒ€ ê¸ˆì§€)
    for idx, spec in enumerate(MODEL_SPECS, 1):
        try:
            print(f"\n[{idx}/{len(MODEL_SPECS)}] {spec['name']} validation ì‹œì‘ (ìˆœì°¨ ì‹¤í–‰)")
            summary = validate_model(spec, log_lines)
            summary_data.append(summary)
            print(f"[{idx}/{len(MODEL_SPECS)}] {spec['name']} validation ì™„ë£Œ")
            
            # ìš”ì•½ í…ìŠ¤íŠ¸ ìƒì„±
            summary_lines.append(f"\n{'='*80}")
            summary_lines.append(f"[{summary['model']}]")
            summary_lines.append(f"  Dataset: {summary['dataset']}")
            summary_lines.append(f"  Task: {summary['task']}")
            summary_lines.append(f"  ì „ì²´ ì‹œê°„: {summary['total_time']:.3f}ì´ˆ")
            if summary['num_images'] > 0:
                summary_lines.append(f"  ì´ë¯¸ì§€ ìˆ˜: {summary['num_images']}")
                summary_lines.append(f"  í‰ê·  ì‹œê°„: {summary['avg_time_per_image_ms']:.3f}ms")
            
            # ë©”íŠ¸ë¦­ ì¶”ê°€
            metrics_str = format_metrics(summary['metrics'], summary['task'])
            if metrics_str:
                summary_lines.append("  ë©”íŠ¸ë¦­:")
                for line in metrics_str.split("\n"):
                    if line.strip():
                        summary_lines.append(line)
            
        except Exception as e:
            error_msg = f"[{spec['name']}] ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            log_lines.append(error_msg)
            log_lines.append("")
            summary_lines.append(error_msg)
            print(f"âŒ {error_msg}")
            import traceback
            log_lines.append(traceback.format_exc())
            log_lines.append("")
    
    # ê²°ê³¼ ì €ì¥
    log_lines.append("\n" + "="*80)
    log_lines.append("Validation ì™„ë£Œ")
    log_lines.append("="*80)
    
    log_path.write_text("\n".join(log_lines), encoding="utf-8")
    txt_path.write_text("\n".join(summary_lines), encoding="utf-8")
    
    # JSON í˜•ì‹ìœ¼ë¡œë„ ì €ì¥ (êµ¬ì¡°í™”ëœ ë°ì´í„°)
    json_path.write_text(
        json.dumps(summary_data, indent=2, ensure_ascii=False),
        encoding="utf-8"
    )
    
    print(f"\nâœ… Validation ì™„ë£Œ!")
    print(f"ğŸ“„ ë¡œê·¸ íŒŒì¼: {log_path}")
    print(f"ğŸ“„ ìš”ì•½ íŒŒì¼: {txt_path}")
    print(f"ğŸ“„ JSON íŒŒì¼: {json_path}")


if __name__ == "__main__":
    main()
